from .exceptions import PipelineException
from . import experiment, notify
from .utils import h5
from . import config
from .utils.decorators import gitlog
from .utils.DLC_tools import smallest_enclosing_circle_naive

from commons import lab

from datajoint.autopopulate import AutoPopulate
from itertools import count
import json
import numpy as np
import cv2
from tqdm import tqdm
from datajoint.jobs import key_hash
import datajoint as dj

import deeplabcut as dlc
from deeplabcut.utils import auxiliaryfunctions
# already configured for cv2
from deeplabcut.utils.video_processor import VideoProcessorCV as vp


import os
# Disable DLC GUI first, then import deeplabcut
os.environ["DLClight"] = "True"

gputouse = 0

schema = dj.schema('pipeline_eye_DLC', locals())

pipeline_eye = dj.create_virtual_module('pipeline_eye', 'pipeline_eye')

# If config.yaml ever updated, make sure you store the file name differently so that it becomes unique
@schema
class ConfigDlc(dj.Manual):
    definition = """
    # Minimal info needed to load deeplabcut model
    config_path                             : varchar(255)          # path to deeplabcut config
    ---
    shuffle                                 : smallint unsigned     # shuffle number used for the trained dlc model. Needed for dlc.analyze_videos
    trainingsetindex                        : smallint unsigned     # trainingset index used for the trained dlc. model. Needed for dlc.analyze_videos
    """


@schema
class TrackedLabelsDlc(dj.Computed):
    definition = """
    #
    -> pipeline_eye.Eye
    -> pipeline_experiment.Scan
    -> ConfigDlc
    ---
    tracking_ts=CURRENT_TIMESTAMP           : timestamp             # automatic
    original_width                          : smallint unsigned     # original video width size
    original_height                         : smallint unsigned     # original video height size
    cropped_x0                              : smallint unsigned     # start coord in width of cropped video
    cropped_x1                              : smallint unsigned     # end coord in width of cropped video
    cropped_y0                              : smallint unsigned     # start coord in height of cropped video
    cropped_y1                              : smallint unsigned     # end coord in height of cropped video
    tracking_dir                            : varchar(255)          # path to tracking directory
    """

    @property
    def key_source(self):

        new_ConfigDlc = ConfigDlc & {
            'config_path': '/mnt/scratch07/donnie/DeepLabCut/pupil_track-Donnie-2019-02-12/config.yaml'}

        new_key_source = (pipeline_eye.Eye * pipeline_experiment.Scan * new_ConfigDlc).proj() & {
            'animal_id': 20892, 'scan_idx': 10, 'session': 9}

        return new_key_source

    def get_video_path(self, key):
        """
        Input:
            key: dictionary
                A key that consists of animal_id, session, and scan_idx
        """
        video_info = (pipeline_experiment.Session() *
                      pipeline_experiment.Scan.EyeVideo() & key).fetch1()
        video_path = lab.Paths().get_local_path(
            "{behavior_path}/{filename}".format(**video_info))
        return video_path

    def create_tracking_directory(self, key):
        """
        this function creates the following directory structure:

        video_original_dir
            |
            |------ video_original
            |------ tracking_dir (create_tracking_folder)
                        |------- symlink to video_original (add_symlink) 
                        |------- cropped_dir
                                    |------- cropped_video (generated from make_short_video)
                                    |------- h5 file for cropped video (generated by dlc)
                                    |------- pickle for cropped video (generated by dlc)
                        |------- short_dir
                                    |------- short_video (generated by make_short_video function)
                                    |------- h5 file for short video(generated by dlc)
                                    |------- pickle for short video (generated by dlc)

        Input:
            case: string 
                a string that contains mouse id, session, and scan idx joined by underscores.
                ex) 20210_2_00015
        Return:
            tracking_dir: string
                a string that specifies the path to the tracking directory
        """

        print("Generating tracking directory for ", key)

        vid_path = self.get_video_path(key)
        vid_dir = os.path.dirname(os.path.normpath(vid_path))
        tracking_dir_name = os.path.basename(
            os.path.normpath(vid_path)).split('.')[0] + '_tracking'

        tracking_dir = os.path.join(vid_dir, tracking_dir_name)

        symlink_path = os.path.join(
            tracking_dir, os.path.basename(os.path.normpath(vid_path)))

        if not os.path.exists(tracking_dir):

            os.mkdir(tracking_dir)
            os.mkdir(os.path.join(tracking_dir, 'cropped'))
            os.mkdir(os.path.join(tracking_dir, 'short'))

            os.symlink(vid_path, symlink_path)

        else:
            print('{} already exists!'.format(tracking_dir))

        return tracking_dir

    def make_short_video(self, tracking_dir):
        """
        Extract 5 seconds long video starting from the middle of the original video.

        Input:
            tracking_dir: string
                String that specifies the full path of tracking directory
        Return:
            None
        """
        from subprocess import Popen, PIPE

        suffix = '_short_beh.avi'

        case = os.path.basename(os.path.normpath(
            tracking_dir)).split('_beh_tracking')[0]

        input_video_path = os.path.join(tracking_dir, case + '_beh.avi')

        # output_vid = case + suffix
        # out_vid_path =  os.path.join(tracking_dir, output_vid)

        out_vid_path = os.path.join(tracking_dir, 'short', case + suffix)

        print('input_video_path is: {}'.format(input_video_path))
        cap = cv2.VideoCapture(input_video_path)

        fps = cap.get(cv2.CAP_PROP_FPS)
        mid_frame_num = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)/2)
        duration = int(mid_frame_num/fps)

        minutes, seconds = divmod(duration, 60)
        hours, minutes = divmod(minutes, 60)

        cmd = ['ffmpeg', '-i', input_video_path, '-ss',
               '{}:{}:{}'.format(hours, minutes, seconds), '-t', '5', '-c', 'copy', out_vid_path]
        # cmd = ['ffmpeg', '-vf' , 'select="between(n\,{},{}),setpts=PTS-STARTPTS"'.format(start_frame, end_frame),
        #     '-i', input_video_path, '-vcodec', 'libx264', out_vid_path]

        # call ffmpeg to make a short video
        p = Popen(cmd, stdin=PIPE)
        # close ffmpeg
        p.wait()

        print("{} was successfully generated".format(out_vid_path))
        return out_vid_path

    def predict_on_short_video(self, short_vid_path, key):
        dlc_config = (ConfigDlc & key).fetch1()
        destfolder = os.path.dirname(short_vid_path)
        dlc.analyze_videos(config=dlc_config['config_path'], videos=[short_vid_path], videotype='avi', shuffle=dlc_config['shuffle'],
                           trainingsetindex=dlc_config['trainingsetindex'], gputouse=gputouse, save_as_csv=False, destfolder=destfolder)

    def obtain_cropping_config(self):
        pass

    def make(self, key):
        print('Tracking labels with DLC')
        config_path = key.pop('config_path')

        tracking_dir = self.create_tracking_directory(key)
        short_vid_path = self.make_short_video(tracking_dir)

        self.predict_on_short_video(short_vid_path, key)

        # config = auxiliaryfunctions.read_config(
        #     (ConfigDlc & key).fetch1('config_path'))

        key['original_width'] = 0
        key['original_height'] = 0
        key['cropped_x0'] = 0
        key['cropped_x1'] = 0
        key['cropped_y0'] = 0
        key['cropped_y1'] = 0
        key['tracking_dir'] = tracking_dir
        key['config_path'] = config_path
        self.insert1(key)

    # class Crop(dj.Part):
    #     definition = """
    #     -> master
    #     frame_id                 : int           # frame id with matlab based 1 indexing
    #     ---
    #     contour=NULL             : longblob      # eye contour relative to ROI
    #     """


@schema
class DLCFittedContour(dj.Computed):
    definition = """
    ---
    fitting_ts=CURRENT_TIMESTAMP    : timestamp  # automatic
    """

    class Ellipse(dj.Part):
        definition = """
        -> master
        frame_id                 : int           # frame id with matlab based 1 indexing
        ---
        center=NULL              : tinyblob      # center of the ellipse in (x, y) of image
        major_r=NULL             : float         # major radius of the ellipse
        minor_r=NULL             : float         # minor radius of the ellipse
        angle=NULL               : float         # ellipse rotation angle in degrees w.r.t. major_r
        visible_portion=NULL     : float         # portion of visible pupil area given a fitted ellipse
        """

    class Circle(dj.Part):
        definition = """
        -> master
        frame_id                 : int           # frame id with matlab based 1 indexing
        ---
        center=NULL              : tinyblob      # center of the circle in (x, y) of image
        radius=NULL              : float         # radius of the circle
        visible_portion=NULL     : float         # portion of visible pupil area given a fitted circle
        """

    def make(self, key):
        print("Populating", key)

        avi_path = (Eye() & key).get_video_path()

        contours = (ManuallyTrackedContours.Frame() & key).fetch(
            order_by='frame_id ASC', as_dict=True)
        self._cap = cap = cv2.VideoCapture(avi_path)

        frame_number = 0
        n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        while cap.isOpened():
            if frame_number >= n_frames - 1:
                print("Reached end of videofile ", avi_path)
                break

            ret, frame = self._cap.read()
            ckey = contours[frame_number]
            if ret and frame is not None and ckey['contour'] is not None:
                if ckey['contour'] is not None and len(ckey['contour']) >= 5:
                    contour = ckey['contour']
                    center = contour.mean(axis=0)
                    cv2.drawContours(frame, [contour], -1, (0, 255, 0), 1)
                    cv2.circle(frame, tuple(
                        center.squeeze().astype(int)), 4, (0, 165, 255), -1)
                    ellipse = cv2.fitEllipse(contour)
                    cv2.ellipse(frame, ellipse, (255, 0, 255), 2)
                    ecenter = ellipse[0]
                    cv2.circle(frame, tuple(map(int, ecenter)),
                               5, (255, 165, 0), -1)
                    ckey['center'] = np.array(ecenter, dtype=np.float32)
                    ckey['major_r'] = max(ellipse[1])
                self.display_frame_number(frame, frame_number, n_frames)
                cv2.imshow('Sauron', frame)
                if (cv2.waitKey(5) & 0xFF) == ord('q'):
                    break
            frame_number += 1
        cap.release()
        cv2.destroyAllWindows()

        self.insert1(key)
        for ckey in tqdm(contours):
            self.Ellipse().insert1(ckey, ignore_extra_fields=True)
